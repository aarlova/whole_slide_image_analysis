{"cells":[{"cell_type":"markdown","id":"d59c11ca-4d04-4fd6-b672-08b1cfaac1b1","metadata":{"id":"d59c11ca-4d04-4fd6-b672-08b1cfaac1b1"},"source":["### Segmentation Inference using saved model on TILES ###"]},{"cell_type":"code","execution_count":null,"id":"6eb0eab7","metadata":{"id":"6eb0eab7"},"outputs":[],"source":["from fastai.basics import *\n","from fastai.vision import *\n","from fastai.vision.core import *\n","from fastai.vision.data import *\n","from fastai.vision import models\n","from fastai.vision.all import *\n","from fastai.metrics import *\n","from fastai.data.all import *\n","from fastai.callback import *\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib\n","from albumentations import ShiftScaleRotate, CoarseDropout, Cutout\n","from albumentations import Compose"]},{"cell_type":"code","execution_count":null,"id":"86fbdc0d","metadata":{"id":"86fbdc0d"},"outputs":[],"source":["model_name = 'deeplabv3+_resnet50_Aug_25_20x_bin_1e-05' # best binary model\n","# model_name = 'hrnet_hrnet_w30_Aug_25_20x_1e-05' # best multiclass model"]},{"cell_type":"code","execution_count":null,"id":"aa5986db","metadata":{"id":"aa5986db"},"outputs":[],"source":["class TargetMaskConvertTransformBinary(ItemTransform):\n","    def __init__(self):\n","        pass\n","    def encodes(self, x):\n","        img,mask = x\n","\n","        #Convert to array\n","        mask = np.array(mask)\n","\n","        # Change 255 for 1\n","        mask[mask == 29] = 1\n","        mask[mask == 71] = 1\n","        mask[mask == 99] = 1\n","        mask[mask == 106] = 1\n","        mask[mask == 111] = 1\n","        mask[mask == 118] = 1\n","        mask[mask == 146] = 1\n","        mask[mask == 154] = 1\n","        mask[mask == 158] = 1\n","        mask[mask == 172] = 1\n","        mask[mask == 178] = 1\n","        mask[mask == 195] = 1\n","        mask[mask == 212] = 1\n","        mask[mask == 223] = 1\n","        mask[mask == 233] = 1\n","        mask[mask == 237] = 1\n","\n","        # Back to PILMask\n","        mask = PILMask.create(mask)\n","\n","\n","        return img, mask"]},{"cell_type":"code","execution_count":null,"id":"1e39faf8","metadata":{"id":"1e39faf8"},"outputs":[],"source":["class SegmentationAlbumentationsTransform(ItemTransform):\n","    split_idx = 0\n","    def __init__(self, aug): self.aug = aug\n","    def encodes(self, x):\n","        img,mask = x\n","        aug = self.aug(image=np.array(img), mask=np.array(mask))\n","        return PILImage.create(aug[\"image\"]), PILMask.create(aug[\"mask\"])"]},{"cell_type":"code","execution_count":null,"id":"0d3374a3","metadata":{"id":"0d3374a3"},"outputs":[],"source":["def PredsToMasksBinary(mask):\n","    #Dataset v2\n","    mask[mask == 1] = 249\n","\n","    return(np.uint8(mask)) # returns np.uint8 array that will be used to create a .png mask"]},{"cell_type":"markdown","id":"95d6c8b8-80f9-46e7-b6ef-64302cd70159","metadata":{"id":"95d6c8b8-80f9-46e7-b6ef-64302cd70159"},"source":["### Specify where predicted Masks wil be saved: ###"]},{"cell_type":"code","execution_count":null,"id":"76a0e22b","metadata":{"id":"76a0e22b"},"outputs":[],"source":["# save predictions as masks\n","def SavePredsMasks(preds, idx):\n","    for i, pred in enumerate(preds[1]):\n","        img_f = foll_test['img'][i+idx]\n","\n","        pred_arg = pred.argmax(dim=0).numpy()\n","        pred_conv = PredsToMasksBinary(pred_arg) # convert to QuPath luminosity values\n","\n","        # save only masks with predictions\n","        if pred_conv.any() == True:\n","            pred_mask = Image.fromarray(pred_conv, 'L')\n","            mask_f = img_f.replace('.jpg', '.png')\n","            save_dir = '/media/14TB/aarlova_ovarian/ovarian demo/demo_segm_preds/'\n","\n","            mask_f = mask_f.replace(str(Path(mask_f).parent), save_dir+(Path(mask_f).parent.stem))\n","\n","            mask_f = Path(mask_f)\n","            mask_f.parent.mkdir(parents=True, exist_ok=True)\n","            new_name = str(mask_f.parent/mask_f.name)\n","\n","            pred_mask.save(new_name)"]},{"cell_type":"code","execution_count":null,"id":"85625446","metadata":{"id":"85625446"},"outputs":[],"source":["## custom accuracy metric (excludes void code aka 'Background')\n","# def acc_follicle(input, target):\n","#     target = target.squeeze(1)\n","#     mask = target != void_code\n","#     a = TensorImage(target[mask])\n","#     return (input.argmax(dim=1)[mask]==a).float().mean()"]},{"cell_type":"markdown","id":"065c0aa7-6cbd-49e0-acd6-d979df9f3f12","metadata":{"id":"065c0aa7-6cbd-49e0-acd6-d979df9f3f12"},"source":["### Import packages and functions required for inference ###"]},{"cell_type":"code","execution_count":null,"id":"f2453258-134a-4f2c-8310-6635667b4474","metadata":{"id":"f2453258-134a-4f2c-8310-6635667b4474"},"outputs":[],"source":["# ###### import for 'AI predicted masks to JSON' (3/14 version)\n","import ovarian_utils\n","from ovarian_utils import MetaPolygon\n","from ovarian_utils import write_qupath_noIDs\n","from ovarian_utils import get_AI_regions\n","from pathlib import Path\n","import numpy as np\n","from shapely.ops import unary_union\n","from collections.abc import Iterable\n","\n"]},{"cell_type":"markdown","id":"6ff18a8b-f0e8-411f-a47d-b451169084e0","metadata":{"id":"6ff18a8b-f0e8-411f-a47d-b451169084e0"},"source":["### Load FastAI learner and model ###"]},{"cell_type":"code","execution_count":null,"id":"959918ab","metadata":{"id":"959918ab","outputId":"c81980d3-9064-4367-87bb-6f7d043064fb"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/aarlova/anaconda3/envs/pytorch_lym_clone/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"]}],"source":["learn = load_learner('/media/14TB/aarlova_ovarian/segmentation/training_log/' + model_name + '.pkl')"]},{"cell_type":"markdown","id":"493e38a6-7512-4182-8fcf-91a6344bc8f3","metadata":{"id":"493e38a6-7512-4182-8fcf-91a6344bc8f3"},"source":["### Recreated dataset and dataloader ###"]},{"cell_type":"code","execution_count":null,"id":"8c54affc-ef57-497a-b25c-b3deb2494973","metadata":{"id":"8c54affc-ef57-497a-b25c-b3deb2494973"},"outputs":[],"source":["#the dataset, and dls (needed for inference)\n","foll = pd.read_csv('/media/14TB/aarlova_ovarian/20x_norm_dgx.csv')\n","segdata = DataBlock(blocks=(ImageBlock),splitter=ColSplitter(),get_x=ColReader('img'),batch_tfms=[Normalize.from_stats(*imagenet_stats), IntToFloatTensor(div_mask = 1)])\n","dls=segdata.dataloaders(foll,bs=6)"]},{"cell_type":"markdown","id":"d426fb07-f11b-4bf3-83f4-a66228c2da1e","metadata":{"id":"d426fb07-f11b-4bf3-83f4-a66228c2da1e"},"source":["### Example of Inference on One Slide ###"]},{"cell_type":"code","execution_count":null,"id":"48fc7602-8f81-474b-892c-bb350458608a","metadata":{"id":"48fc7602-8f81-474b-892c-bb350458608a","outputId":"ce1572c4-2a65-4c7a-dc0b-4944c2e0d3b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["These tile directories will be processed:\n","/raid/aarlova/2000slides/tiles20x/17133893\n"]}],"source":["imgs = ['17133893']\n","\n","dir_list = ['/raid/aarlova/2000slides/tiles20x/'+i for i in imgs]\n","print('These tile directories will be processed:')\n","for d in dir_list:\n","    print(d)"]},{"cell_type":"code","execution_count":null,"id":"586d34d4-9051-46bf-9d71-f3816bcefe6d","metadata":{"id":"586d34d4-9051-46bf-9d71-f3816bcefe6d"},"outputs":[],"source":["# ####### Label Dictionary for Binary masks\n","label_dict = {249: 'Follicle', 1: 'Follicle'}\n","region_colors = {'Follicle': -3348737}\n","\n","mask_dir = Path('/media/14TB/aarlova_ovarian/ovarian demo/demo_segm_preds/')\n","json_save_dir = '/media/14TB/aarlova_ovarian/ovarian demo/demo_segm_preds/'"]},{"cell_type":"code","execution_count":null,"id":"d52b9669-c785-4121-86c6-37bcab7343f7","metadata":{"id":"d52b9669-c785-4121-86c6-37bcab7343f7","outputId":"53172992-4942-4ec7-d264-529840dbacba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Segmentation Inference on tile dir /raid/aarlova/2000slides/tiles20x/17133893\n","Length of this dataset is 2028\n","<bound method NDFrame.head of                                                                                            img\n","0     /raid/aarlova/2000slides/tiles20x/17133893/17133893 [x=105464,y=37196,w=1000,h=1000].jpg\n","1     /raid/aarlova/2000slides/tiles20x/17133893/17133893 [x=104564,y=41696,w=1000,h=1000].jpg\n","2     /raid/aarlova/2000slides/tiles20x/17133893/17133893 [x=138916,y=45796,w=1000,h=1000].jpg\n","3      /raid/aarlova/2000slides/tiles20x/17133893/17133893 [x=20584,y=33604,w=1000,h=1000].jpg\n","4     /raid/aarlova/2000slides/tiles20x/17133893/17133893 [x=181536,y=15332,w=1000,h=1000].jpg\n","...                                                                                        ...\n","2023   /raid/aarlova/2000slides/tiles20x/17133893/17133893 [x=21484,y=40804,w=1000,h=1000].jpg\n","2024   /raid/aarlova/2000slides/tiles20x/17133893/17133893 [x=61624,y=12940,w=1000,h=1000].jpg\n","2025    /raid/aarlova/2000slides/tiles20x/17133893/17133893 [x=90000,y=7744,w=1000,h=1000].jpg\n","2026   /raid/aarlova/2000slides/tiles20x/17133893/17133893 [x=90900,y=12244,w=1000,h=1000].jpg\n","2027   /raid/aarlova/2000slides/tiles20x/17133893/17133893 [x=17712,y=15532,w=1000,h=1000].jpg\n","\n","[2028 rows x 1 columns]>\n","Number of batches in test dataset 9\n","batch # 0 out of  9\n","length of batched test set 250\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["batch # 1 out of  9\n","length of batched test set 250\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["batch # 2 out of  9\n","length of batched test set 250\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["batch # 3 out of  9\n","length of batched test set 250\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["batch # 4 out of  9\n","length of batched test set 250\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["batch # 5 out of  9\n","length of batched test set 250\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["batch # 6 out of  9\n","length of batched test set 250\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["batch # 7 out of  9\n","length of batched test set 250\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["batch # 8 out of  9\n","length of batched test set 28\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Done with Inference!\n","Creating JSON at /media/14TB/aarlova_ovarian/ovarian demo/demo_segm_preds/17133893.json\n","This folder has predictions\n"]},{"name":"stderr","output_type":"stream","text":["/media/14TB/aarlova_ovarian/ovarian demo/ovarian_utils.py:23: ShapelyDeprecationWarning: Setting custom attributes on geometry objects is deprecated, and will raise an AttributeError in Shapely 2.0\n","  self.label = label\n","/media/14TB/aarlova_ovarian/ovarian demo/ovarian_utils.py:24: ShapelyDeprecationWarning: Setting custom attributes on geometry objects is deprecated, and will raise an AttributeError in Shapely 2.0\n","  self.id = id\n"]},{"name":"stdout","output_type":"stream","text":["done with slide\n","Detected class Follicle\n","detected before union 545\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-19-da90a9536e9e>:83: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n","  current_label_polygons_union_with_label = [MetaPolygon(label, p) for p in current_label_polygons_union]\n"]},{"name":"stdout","output_type":"stream","text":["detected after union 391\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Failed to infer: 0 []\n"]}],"source":["# create a test dataset from list of paths to test tiles and put into a simple DataFrame\n","failed = []\n","\n","for d in dir_list:\n","    try:\n","\n","        dir = Path(d)\n","        print('Segmentation Inference on tile dir', dir)\n","        paths = []\n","        for file in dir.iterdir():\n","            if file.suffix == '.jpg':\n","                paths.append(str(file.absolute()))\n","\n","        df = pd.DataFrame()\n","        df['img'] = paths\n","\n","        df.head()\n","\n","        foll_test_ds = df\n","\n","\n","        print('Length of this dataset is',len(foll_test_ds))\n","        print(foll_test_ds.head)\n","\n","        bs = 250\n","        n_batches = int(np.ceil(len(foll_test_ds)/bs))\n","        print('Number of batches in test dataset', n_batches)\n","\n","        # inference loop\n","        current = 0\n","\n","        for i in range(n_batches):\n","            # get a chunk of data from test dataset\n","            print('batch #', i, 'out of ', n_batches)\n","            foll_test = foll_test_ds[current:current+bs]\n","            print('length of batched test set', len(foll_test))\n","\n","            # inference\n","            test_dl = dls.test_dl(foll_test, with_labels = False)\n","            preds = learn.get_preds(dl=test_dl, with_input = True)\n","            SavePredsMasks(preds, current)\n","\n","            current += bs\n","\n","        print('Done with Inference!')\n","\n","        ############### if no masks were predicted, create an empty directory ###############\n","        save_dir = Path('/media/14TB/aarlova_ovarian/ovarian demo/demo_segm_preds/' + dir.stem)\n","        save_dir.mkdir(parents=True, exist_ok=True)\n","\n","\n","\n","        ############### convert masks to json ###############\n","        min_area = 5000\n","\n","        json_save = json_save_dir + str(dir.name) + '.json'\n","        print('Creating JSON at', json_save)\n","\n","        AI_slide_polygons = get_AI_regions(Path(mask_dir/dir.name))\n","        AI_slide_labels = np.unique([p.label for p in AI_slide_polygons])\n","\n","        regions = []\n","        region_labels = []\n","\n","        for label in AI_slide_labels:\n","            print('Detected class', label)\n","            if label == 'Antral':\n","                buffer = 1.5\n","                current_label_polygons = [p.buffer(buffer) for p in AI_slide_polygons if (p.label == label and p.area > 50000)]\n","            else:\n","                buffer = 1.5\n","                # find all polys with this label and unary_union them\n","                current_label_polygons = [p.buffer(buffer) for p in AI_slide_polygons if (p.label == label and p.area > min_area)]\n","            print('detected before union',len(current_label_polygons))\n","\n","            # unary_union on polygons of the same label\n","            if len(current_label_polygons) > 1:\n","                current_label_polygons_union = unary_union(current_label_polygons)\n","\n","                if not isinstance(current_label_polygons_union, Iterable):\n","                    current_label_polygons_union = [current_label_polygons_union]\n","\n","                current_label_polygons_union_with_label = [MetaPolygon(label, p) for p in current_label_polygons_union]\n","\n","                # convert to regions and regions_labels\n","                for p in current_label_polygons_union_with_label:\n","                    new_ext_x = np.array(p.exterior.coords.xy[0])\n","                    new_ext_y = np.array(p.exterior.coords.xy[1])\n","\n","                    new_coords = list(zip(new_ext_x, new_ext_y))\n","                    new_label = p.label\n","                    regions.append(new_coords)\n","                    region_labels.append(new_label)\n","                print('detected after union', len(current_label_polygons_union_with_label))\n","\n","            elif len(current_label_polygons) == 0:\n","                pass\n","\n","            else:\n","                new_ext_x = np.array(current_label_polygons[0].exterior.coords.xy[0])\n","                new_ext_y = np.array(current_label_polygons[0].exterior.coords.xy[1])\n","\n","                new_coords = list(zip(new_ext_x, new_ext_y))\n","                new_label = label\n","                regions.append(new_coords)\n","                region_labels.append(new_label)\n","\n","        ids = [i for i in range(len(regions))]\n","        write_qupath_noIDs(json_save, regions,region_labels,region_colors)\n","        print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n","\n","    except:\n","        failed.append(d)\n","\n","print('Failed to infer:', len(failed), failed)"]}],"metadata":{"kernelspec":{"display_name":"pytorch_lym_clone","language":"python","name":"pytorch_lym_clone"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}